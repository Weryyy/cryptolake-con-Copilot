# ğŸ”ï¸ CryptoLake â€” Real-Time Crypto Analytics Lakehouse

[![CI Pipeline](https://github.com/Weryyy/cryptolake-con-Copilot/actions/workflows/ci.yml/badge.svg)](https://github.com/Weryyy/cryptolake-con-Copilot/actions/workflows/ci.yml)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![dbt](https://img.shields.io/badge/dbt-1.8-FF694B?logo=dbt)](https://www.getdbt.com/)
[![Apache Iceberg](https://img.shields.io/badge/Apache_Iceberg-1.5-blue)](https://iceberg.apache.org/)

> An end-to-end data engineering platform that ingests real-time and historical
> cryptocurrency data, processes it through a **Medallion Architecture** (Bronze â†’ Silver â†’ Gold)
> on **Apache Iceberg**, transforms with **dbt**, orchestrates with **Airflow**, and serves
> analytics via **REST API** and interactive **dashboard** â€” all containerized with Docker.

---

## ğŸ¯ Objetivo del Proyecto
El objetivo principal de **CryptoLake** es proporcionar una plataforma de datos robusta, escalable y de baja latencia para el anÃ¡lisis del mercado de criptomonedas. El proyecto demuestra la implementaciÃ³n de patrones modernos de ingenierÃ­a de datos, integrando:
*   **Ingesta HÃ­brida**: Captura de eventos en tiempo real (Binance) y lotes histÃ³ricos (CoinGecko).
*   **Eficiencia de Almacenamiento**: Uso de **Apache Iceberg** para manejar transacciones ACID, evoluciÃ³n de esquemas y compactaciÃ³n de datos.
*   **Gobernanza y Calidad**: Transformaciones estructuradas con **dbt** y validaciones de calidad con **Great Expectations** en cada capa.
*   **Machine Learning**: Sistema Ensemble multi-modelo con predicciÃ³n dual (Legacy TFT + Ensemble) y reentrenamiento automÃ¡tico.
*   **Servicio de Datos**: ProvisiÃ³n de mÃ©tricas refinadas a travÃ©s de una API de alto rendimiento y un dashboard interactivo.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         DATA SOURCES                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Binance WS   â”‚  â”‚ CoinGecko    â”‚  â”‚ Alternative.me            â”‚  â”‚
â”‚  â”‚ (Real-time)  â”‚  â”‚ (Historical) â”‚  â”‚ (Fear & Greed Index)      â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
          â”‚                 â”‚                        â”‚
          â–¼                 â–¼                        â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   KAFKA          â”‚  â”‚   PYTHON EXTRACTORS                  â”‚
â”‚   (Streaming)    â”‚  â”‚   (Batch via Airflow)                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                          â”‚
         â–¼                          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 LAKEHOUSE (MinIO + Apache Iceberg)                    â”‚
â”‚                                                                      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ ğŸ¥‰ BRONZE   â”‚    â”‚ ğŸ¥ˆ SILVER    â”‚    â”‚ ğŸ¥‡ GOLD               â”‚  â”‚
â”‚  â”‚ (Raw)       â”‚â”€â”€â”€â–¶â”‚ (Cleaned)    â”‚â”€â”€â”€â–¶â”‚ (Star Schema)         â”‚  â”‚
â”‚  â”‚ Iceberg     â”‚    â”‚ Iceberg      â”‚    â”‚ Iceberg + dbt         â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚         â–²                  â–²                       â–²                 â”‚
â”‚    Spark Streaming    Spark Batch              dbt models            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚  FastAPI      â”‚  â”‚  Streamlit    â”‚  â”‚  ML Pipeline â”‚
    â”‚  REST API     â”‚  â”‚  Dashboard    â”‚  â”‚  (Ensemble)  â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Streaming** | Apache Kafka | Real-time price ingestion from Binance |
| **Processing** | Apache Spark (PySpark) | Batch + stream processing |
| **Table Format** | Apache Iceberg | ACID transactions, time travel, schema evolution |
| **Storage** | MinIO (S3-compatible) | Object storage for Lakehouse |
| **Transformation** | dbt-core + dbt-spark | SQL-based dimensional modeling (Kimball) |
| **Orchestration** | Apache Airflow | Pipeline scheduling and monitoring |
| **Data Quality** | Great Expectations | Automated data validation per layer |
| **ML** | PyTorch + scikit-learn | Ensemble predictive models (GB + RF + LSTM) |
| **API** | FastAPI | REST API for analytics + ML inference |
| **Dashboard** | Streamlit + Plotly | Interactive visualizations with line toggles |
| **Containers** | Docker + Docker Compose | Reproducible deployment |
| **IaC** | Terraform | Infrastructure as Code |
| **CI/CD** | GitHub Actions | Automated linting, testing and builds |
| **Monitoring** | Prometheus + Grafana | Pipeline observability |
| **Code Quality** | Ruff + mypy + pre-commit | Linting + type checking |

## ğŸš€ Quick Start

```bash
# Clone the repository
git clone https://github.com/Weryyy/cryptolake-con-Copilot.git
cd cryptolake-con-Copilot

# Copy environment variables
cp .env.example .env

# Start all 12+ services with one command
make up

# Create Kafka topics
make kafka-create-topics

# Verify everything is running
python scripts/health_check.py
```

## ğŸ§  Machine Learning: Ensemble Multi-Modelo

CryptoLake utiliza un sistema **Ensemble multi-modelo** con predicciÃ³n dual para mÃ¡xima fiabilidad:

### Modelo Ensemble (Principal)
| Componente | Peso | DescripciÃ³n |
|------------|------|-------------|
| **GradientBoosting** | ~47% | ClasificaciÃ³n de direcciÃ³n (sube/baja) con probabilidad |
| **RandomForest** | ~15% | ConfirmaciÃ³n y diversidad |
| **ReturnLSTM** | ~38% | Magnitud del retorno + direcciÃ³n con self-attention |

### Modelo Legacy TFT (A/B Testing)
- **Temporal Fusion Transformer** con dos memorias:
  - **Memoria HistÃ³rica** (`--mode historical`): 200 Ã©pocas. Estabilidad macro.
  - **Memoria Reciente** (`--mode recent`): 400 Ã©pocas. Sensibilidad micro.

### Features (20 indicadores engineered)
Retornos multi-lag, volatilidad, RSI, MACD, Bandas de Bollinger, ratio de volumen, momentum, Fear & Greed normalizado, y codificaciÃ³n cÃ­clica de hora del dÃ­a.

### PrecisiÃ³n
- **Ensemble**: ~60% direcciÃ³n (71% filtrando por confianza > 0.2)
- **Reentrenamiento automÃ¡tico**: Cada 6 horas vÃ­a Airflow + API async

### Training Commands
```bash
make train-ml-all      # Ensemble + TFT + restart inference
make train-ensemble    # Solo ensemble
make train-tft         # Solo TFT (historical + recent)
```

## ğŸ“Š Dashboard Interactivo

El dashboard Streamlit incluye **7 secciones** con auto-refresco y controles de visibilidad:

| PÃ¡gina | DescripciÃ³n |
|--------|-------------|
| **Market Overview** | Precios actuales, predicciÃ³n AI dual, candlestick BTC real-time, accuracy del mejor modelo |
| **Price Charts** | Velas intradÃ­a OHLC + precio histÃ³rico por criptomoneda |
| **Coin Comparison** | Precio normalizado, mÃ©tricas lado a lado, volumen comparativo |
| **Fear & Greed Index** | Gauge de sentimiento + grÃ¡fico de barras histÃ³rico |
| **Trading Signals** | SeÃ±ales combinadas: AI + sentimiento + fiabilidad del modelo |
| **Logs & System** | Data Quality (GX), alertas del sistema tipo Slack, info de hardware |

**Funcionalidades clave:**
- ğŸ”€ Toggles para mostrar/ocultar lÃ­neas individuales del grÃ¡fico
- ğŸ“ˆ LÃ­nea verde EMA (Exponential Moving Average) como mejora de predicciÃ³n
- ğŸ† Gauge automÃ¡tico del mejor modelo del dÃ­a
- ğŸ” Zoom persistente con rendering HTML nativo de Plotly

### Services Dashboard

| Service | URL | Credentials |
|---------|-----|-------------|
| **MinIO Console** | http://localhost:9001 | `cryptolake` / `cryptolake123` |
| **Kafka UI** | http://localhost:8080 | â€” |
| **Spark UI** | http://localhost:8082 | â€” |
| **Airflow** | http://localhost:8083 | `admin` / `admin` |
| **API Docs** | http://localhost:8000/docs | â€” |
| **Dashboard** | http://localhost:8501 | â€” |
| **Grafana** | http://localhost:3000 | `admin` / `cryptolake` |

## ğŸ”Œ API Endpoints

| Endpoint | Method | DescripciÃ³n |
|----------|--------|-------------|
| `/api/v1/analytics/market-overview` | GET | Vista general del mercado |
| `/api/v1/analytics/prediction` | GET | PredicciÃ³n principal |
| `/api/v1/analytics/dual-prediction` | GET | Legacy vs Ensemble side-by-side |
| `/api/v1/analytics/model-comparison` | GET | Accuracy metrics por modelo |
| `/api/v1/analytics/prediction-history/{model}` | GET | Historial de predicciones |
| `/api/v1/analytics/realtime-ohlc/{coin_id}` | GET | Velas intradÃ­a 4h |
| `/api/v1/analytics/fear-greed-history` | GET | HistÃ³rico Fear & Greed |
| `/api/v1/analytics/dq-reports` | GET | Reportes Data Quality |
| `/api/v1/analytics/system-alerts` | GET | Alertas del sistema |
| `/api/v1/ml/retrain?mode=ensemble` | POST | Trigger reentrenamiento async |
| `/api/v1/ml/retrain-status` | GET | Estado del reentrenamiento |
| `/api/v1/health/latency` | GET | Latencia por capa del lakehouse |

## ğŸ” OrchestraciÃ³n (Airflow DAGs)

| DAG | Schedule | DescripciÃ³n |
|-----|----------|-------------|
| **`dag_full_pipeline`** | Diario @06:00 UTC | Batch extractors â†’ Bronze â†’ Silver â†’ dbt Gold â†’ DQ gates |
| **`dag_ml_retrain`** | Cada 6 horas | Retrain ensemble vÃ­a API â†’ polling status â†’ log resultados |
| **`dag_ml_training`** | Manual | Training separado (legacy) |
| **`iceberg_maintenance`** | Diario @02:00 UTC | CompactaciÃ³n de micro-archivos + expiraciÃ³n de snapshots |

## ğŸ›¡ï¸ Troubleshooting

Si encuentras problemas al levantar el entorno (errores de Spark, fallos de dependencias en Airflow o el Dashboard), consulta el documento de [Troubleshooting Log](docs/troubleshooting_log.md). Contiene una lista de errores comunes y sus soluciones tÃ©cnicas.

## ğŸ“Š Data Model

### Medallion Architecture

| Layer | Content | Format | Processing |
|-------|---------|--------|------------|
| **Bronze** | Raw data, unmodified | Iceberg (append-only) | Spark Streaming + Batch |
| **Silver** | Cleaned, deduplicated, typed | Iceberg (merge) | Spark Batch |
| **Gold** | Dimensional model (star schema) | Iceberg | dbt |

### Star Schema (Gold Layer)

- **`fact_market_daily`** â€” Daily crypto market metrics (price, volume, MAs, sentiment)
- **`fact_price_hourly`** â€” Hourly OHLCV from streaming data
- **`market_ohlc`** â€” Multi-period OHLC (1h, 4h, 1d candles pre-computed)
- **`dim_coins`** â€” Cryptocurrency metadata and statistics
- **`dim_dates`** â€” Calendar dimension

### dbt Models (10 SQL models)

| Layer | Models |
|-------|--------|
| **Staging** | `stg_prices`, `stg_market_metrics`, `stg_fear_greed` |
| **Intermediate** | `int_market_enriched`, `int_price_daily_agg` |
| **Marts** | `fact_market_daily`, `fact_price_hourly`, `market_ohlc`, `dim_coins`, `dim_dates` |

## ğŸ“ˆ Key Features

- **Dual Pipeline**: Real-time streaming (Kafka â†’ Spark Streaming) + daily batch
- **Lakehouse Architecture**: Apache Iceberg with Medallion pattern (Bronze â†’ Silver â†’ Gold)
- **Dimensional Modeling**: Kimball star schema with facts and dimensions
- **Ensemble ML**: Multi-model predictions with dual A/B testing (Ensemble + Legacy TFT)
- **Data Contracts**: Schema versioning and quality agreements between layers
- **Incremental Processing**: `MERGE INTO` for efficient Silver layer updates
- **Data Quality Gates**: Great Expectations validation suites with dashboard reporting
- **Interactive Dashboard**: 7 pages, line toggles, zoom persistence, auto-refresh
- **Automated Retraining**: Airflow DAG triggers ensemble retrain every 6 hours
- **Production-Ready**: CI/CD, monitoring, alerting, structured logging

## ğŸ—‚ï¸ Project Structure

```
cryptolake/
â”œâ”€â”€ .github/workflows/       # CI/CD pipelines (lint, test, dbt, docker)
â”œâ”€â”€ docker/                  # Dockerfiles (Spark, Airflow, API, Prometheus)
â”œâ”€â”€ terraform/               # Infrastructure as Code
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/              # Centralized settings (Pydantic)
â”‚   â”œâ”€â”€ ingestion/           # Streaming (Kafka) + Batch extractors
â”‚   â”œâ”€â”€ processing/          # Spark jobs (Bronze, Silver, VWAP)
â”‚   â”œâ”€â”€ transformation/      # dbt models (10 SQL: staging, intermediate, marts)
â”‚   â”œâ”€â”€ orchestration/       # Airflow DAGs (pipeline, ML retrain, maintenance)
â”‚   â”œâ”€â”€ quality/             # Great Expectations DQ engine + validators
â”‚   â”œâ”€â”€ serving/             # FastAPI + Streamlit dashboard
â”‚   â””â”€â”€ ml/                  # Ensemble training, inference, features (20)
â”œâ”€â”€ models/                  # Pre-trained ML models (TFT, GB, RF, LSTM)
â”œâ”€â”€ tests/                   # Unit + Integration tests
â”œâ”€â”€ docs/                    # Architecture, data dictionary, contracts
â”œâ”€â”€ scripts/                 # Setup and utility scripts
â”œâ”€â”€ docker-compose.yml       # Full local environment (12+ services)
â”œâ”€â”€ Makefile                 # Developer commands
â””â”€â”€ pyproject.toml           # Python project configuration
```

## ğŸ§ª Development

```bash
# Create virtual environment
python3.11 -m venv .venv
source .venv/bin/activate

# Install dependencies (including dev tools)
pip install -e ".[dev]"

# Run tests
make test

# Run linting
make lint

# Format code
make format

# Run the full pipeline manually
make pipeline
```

## ğŸ“ Documentation

- [Architecture Decision Records](docs/architecture.md)
- [Data Dictionary](docs/data_dictionary.md)
- [Setup Guide](docs/setup_guide.md)
- [Data Contracts](docs/data_contracts/)
- [Troubleshooting Log](troubleshooting_log.md)

---

## ğŸš€ Roadmap y Optimizaciones
Estamos evolucionando el proyecto con las siguientes mejoras crÃ­ticas:

### 1. OptimizaciÃ³n del Almacenamiento (Iceberg Tuning)
*   **Hidden Partitioning & Sort Orders**: ImplementaciÃ³n de `SORTED BY (timestamp)` en archivos Iceberg para maximizar el *data skipping* con PyArrow.
*   **Compaction DAG**: âœ… AutomatizaciÃ³n con Airflow para ejecutar `rewriteDataFiles`, consolidando micro-archivos de streaming.

### 2. Algoritmos de Rendimiento
*   **VWAP en Tiempo Real**: âœ… CÃ¡lculo distribuido del precio promedio ponderado por volumen en ventanas deslizantes (`silver.realtime_vwap`).
*   **DetecciÃ³n de AnomalÃ­as**: Capa de QA que utiliza Z-Score para identificar variaciones sospechosas.

### 3. Analytics Avanzado (Gold Layer)
*   **Modelos OHLC**: âœ… Agregaciones dbt para velas de 1h, 4h y 1d en `market_ohlc`.
*   **API Hot-Path**: MigraciÃ³n de consultas pesadas a tablas Gold pre-agregadas.

### 4. CachÃ© de Baja Latencia
*   **Redis Integration**: âœ… Almacenamiento en cachÃ© de alertas, DQ reports y estado de reentrenamiento.

---

## ğŸ“œ License

This project is licensed under the MIT License â€” see the [LICENSE](LICENSE) file for details.
