# üìì Registro de Errores y Lecciones Aprendidas ‚Äî CryptoLake

Este documento detalla los fallos t√©cnicos, errores de configuraci√≥n y problemas de compatibilidad encontrados durante el desarrollo del proyecto y c√≥mo se resolvieron.

## 1. Capa de Serving (FastAPI)

### ‚ùå Error de Dependencias en el Contenedor
- **Problema**: El contenedor `api` no ten√≠a instaladas las librer√≠as necesarias para conectarse a Iceberg (`pyiceberg`) ni para procesar datos tabulares (`pyarrow`, `s3fs`).
- **Error**: `ModuleNotFoundError: No module named 'pyiceberg'`.
- **Soluci√≥n**: Se actualizaron los requerimientos en `docker/api/Dockerfile` y se reconstruy√≥ la imagen incluyendo `pyiceberg[s3fs,pyarrow]`.

### ‚ùå Incompatibilidad de Atributos en PyArrow
- **Problema**: Se intent√≥ usar `pyarrow.compute.max_element_index()` para encontrar el registro m√°s reciente, pero la versi√≥n instalada en el contenedor no inclu√≠a ese atributo.
- **Error**: `AttributeError: module 'pyarrow.compute' has no attribute 'max_element_index'`.
- **Soluci√≥n**: Se cambi√≥ la l√≥gica t√©cnica a un ordenamiento manual basado en Python (`sorted(rows, key=lambda x: x["date"], reverse=True)[0]`), garantizando robustez entre versiones.

### ‚ùå Schema Mismatch (Fear & Greed)
- **Problema**: La API esperaba una columna `value_classification`, pero la tabla en Iceberg (creada por Spark) usaba simplemente `classification`.
- **Error**: `KeyError: 'value_classification'`.
- **Soluci√≥n**: Se ejecut√≥ un `DESCRIBE TABLE` en Spark para validar el schema real y se actualiz√≥ el c√≥digo de la ruta en `src/serving/api/routes/analytics.py`.

---

## 2. Ingesta y Procesamiento (Spark/Iceberg)

### ‚ùå Error de Resoluci√≥n de Host
- **Problema**: Los scripts intentaban conectar al cat√°logo de Iceberg usando `localhost:8181`, lo cual fallaba desde dentro de los contenedores Docker.
- **Error**: `ConnectionRefusedError` o nombres de host no encontrados (`spark-iceberg`).
- **Soluci√≥n**: Se estandarizaron los nombres de los servicios en `docker-compose.yml` (ej: `iceberg-rest` y `spark-master`) y se usaron las variables de entorno para inyectar los nombres de host correctos.

### ‚ùå L√≠mite de Velocidad de API (Rate Limiting)
- **Problema**: CoinGecko devolv√≠a errores al intentar descargar 365 d√≠as de historia para m√∫ltiples monedas simult√°neamente.
- **Error**: `HTTP 429 Too Many Requests`.
- **Soluci√≥n**: Se redujo el rango de descarga inicial a 90 d√≠as y se a√±adi√≥ l√≥gica de espera (`time.sleep`) entre llamadas en los extractores batch.

### ‚ùå Falta de JARs para Streaming
- **Problema**: Spark no pod√≠a leer de Kafka porque faltaba el conector Maven necesario.
- **Error**: `java.lang.ClassNotFoundException: org.apache.spark.sql.kafka010.KafkaSourceProvider`.
- **Soluci√≥n**: Se a√±adi√≥ el par√°metro `--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0` al comando `spark-submit` en el job de streaming.

---

## 3. Infraestructura y Docker

### ‚ùå Configuraci√≥n de S3 (MinIO)
- **Problema**: PyIceberg y Spark ten√≠an problemas para encontrar los buckets si no se especificaba el `path-style access`.
- **Soluci√≥n**: Se forz√≥ `s3.path-style-access: "true"` en todas las configuraciones de cat√°logo para asegurar compatibilidad con MinIO.

### ‚ùå Persistencia de Datos
- **Problema**: Al reiniciar los contenedores sin vol√∫menes definidos, el cat√°logo de Iceberg perd√≠a el estado de las tablas aunque los archivos estuvieran en MinIO.
- **Soluci√≥n**: Se aseguraron vol√∫menes persistentes para `minio-data` y se configur√≥ el cat√°logo REST para ser la "fuente de verdad".

---

## 4. Dashboard & Serving (Streamlit / FastAPI) ‚Äî Fase 5

### ‚ùå Gr√°ficos de Precio Hist√≥rico Desordenados para Non-BTC Coins
- **Problema**: Los gr√°ficos de precio hist√≥rico para ethereum, solana y otras monedas distintas de bitcoin aparec√≠an con un aspecto "raro" ‚Äî las l√≠neas zigzagueaban de forma ca√≥tica.
- **Causa ra√≠z**: El endpoint `/prices/{coin_id}` devolv√≠a datos de Iceberg sin ordenar. Los datos del scan de PyIceberg no garantizan orden, y las filas sal√≠an mezcladas (ej: Feb 20, 21, 22, 23, 13, 14, 15...). Al renderizar un `px.line()` con fechas desordenadas, la l√≠nea iba y ven√≠a.
- **Error visual**: El chart de Ethereum mostraba una l√≠nea que saltaba entre fechas de forma aleatoria en vez de una curva suave.
- **Soluci√≥n**: Se a√±adi√≥ `df.sort(key=lambda x: str(x.get("price_date", "")))` en `src/serving/api/routes/prices.py` antes de devolver los resultados, tanto en la query principal (Gold) como en el fallback (Silver).

### ‚ùå Error OHLC Read Timeout en Dashboard
- **Problema**: El dashboard mostraba frecuentemente el error `Error OHLC: HTTPConnectionPool(host='api', port=8000): Read timed out. (read timeout=5)` en la barra lateral.
- **Causa ra√≠z**: El timeout de `requests.get()` para el endpoint OHLC en tiempo real estaba configurado a solo 5 segundos. Las queries a Iceberg (especialmente `silver.realtime_vwap` con filtros de timestamp ISO-8601) pueden tardar m√°s de 5s en responder, especialmente si el cat√°logo REST necesita refrescar metadatos o la tabla tiene muchos snapshots.
- **Soluci√≥n**: Se increment√≥ el timeout de todas las llamadas HTTP del dashboard de 5s a 15s (o se a√±adi√≥ `timeout=15` donde no exist√≠a). Archivos afectados: `src/serving/dashboard/app.py` ‚Äî `fetch_realtime_ohlc()`, `fetch_market_overview()`, `fetch_fear_greed()`, `fetch_price_history()`, `fetch_prediction()`, `fetch_prediction_accuracy()`, `fetch_system_alerts()`, `fetch_dq_reports()`.

### ‚ö†Ô∏è Model Accuracy Panel Muestra 0 Evaluaciones
- **Problema**: El panel de precisi√≥n del modelo (Model Accuracy) en Market Overview mostraba "Recopilando datos de precisi√≥n..." permanentemente con `total_evaluated: 0`.
- **Causa ra√≠z**: La funci√≥n `_evaluate_past_predictions()` en `inference_service.py` eval√∫a predicciones de 30-120 segundos de antig√ºedad. Si el servicio ML se reinici√≥ recientemente o no ha acumulado suficientes predicciones en Redis (key `prediction_history`), no hay nada que evaluar. Adem√°s, el timeout de 5s anterior imped√≠a que la llamada al endpoint de accuracy completara correctamente.
- **Soluci√≥n**: (1) Se aument√≥ el timeout a 15s para dar tiempo a la API. (2) El panel ahora muestra un mensaje informativo indicando que las m√©tricas aparecer√°n tras ~2 minutos de predicciones continuas. No es un error ‚Äî es comportamiento esperado cuando el servicio ML acaba de arrancar.

### ‚ùå Alertas del Sistema Sin Fecha
- **Problema**: En la secci√≥n "Logs & System Status", las alertas del sistema solo mostraban la hora (`HH:MM:SS`) sin la fecha, haciendo imposible saber si un error era de hoy o de d√≠as anteriores.
- **Soluci√≥n**: Se cambi√≥ el formato de timestamp de `'%H:%M:%S'` a `'%Y-%m-%d %H:%M:%S'` en `src/serving/dashboard/app.py` para mostrar fecha y hora completa.

### ‚ùå Falta de Datos Hist√≥ricos en Fear & Greed Index
- **Problema**: La p√°gina de Fear & Greed Index solo mostraba el valor actual con un gauge, sin contexto hist√≥rico. Era imposible entender la tendencia que llev√≥ al √≠ndice a su estado actual.
- **Soluci√≥n**: Se cre√≥ un nuevo endpoint `/api/v1/analytics/fear-greed-history` que devuelve todos los registros de `bronze.fear_greed_index` ordenados por timestamp. Se a√±adi√≥ un gr√°fico de barras con color-coding (rojo oscuro = extreme fear, verde = extreme greed) y l√≠neas de referencia horizontales en 25, 50 y 75.

### ‚ö†Ô∏è Falta de Descripciones en Navegaci√≥n del Dashboard
- **Problema**: Las secciones del dashboard no ten√≠an descripci√≥n, y el usuario no sab√≠a qu√© pod√≠a ver en cada apartado sin entrar.
- **Soluci√≥n**: Se a√±adi√≥ un cuadro informativo (`st.info()`) al inicio de cada p√°gina explicando qu√© se puede ver, y una descripci√≥n corta en el sidebar debajo del selector de navegaci√≥n.

### ‚ùå Model Accuracy Siempre en 0 ‚Äî Evaluaci√≥n Duplicada y Contenedor Sin Reiniciar
- **Problema**: El panel de precisi√≥n del modelo (Model Accuracy) nunca mostraba datos reales; siempre aparec√≠a "Recopilando datos de precisi√≥n..." o `total_evaluated: 0`. Cuando finalmente funcion√≥, las m√©tricas estaban infladas (9 evaluaciones de lo que deber√≠an ser 3 predicciones) con `direction_accuracy: 0%`.
- **Causa ra√≠z (doble)**:
  1. **Contenedor no reiniciado**: El servicio `ml-inference` monta `./src:/app/src` como volumen, por lo que el *archivo* `.py` se actualiza en caliente. Sin embargo, el *proceso Python* que ya est√° corriendo carg√≥ el m√≥dulo en memoria al arrancar. Un simple `docker compose restart ml-inference` era necesario para que Python reimportara el c√≥digo actualizado con `prediction_history` y `_evaluate_past_predictions`. El auto-refresh de Streamlit (30s) NO causa este problema ‚Äî solo refresca el frontend.
  2. **Evaluaci√≥n duplicada**: La funci√≥n `_evaluate_past_predictions()` comprobaba `entry.get("evaluated")` pero NUNCA marcaba las entradas como evaluadas en Redis. En cada ciclo de 30s, el bucle volv√≠a a leer las mismas predicciones de `prediction_history` (que est√°n en la ventana 30-120s) y las contaba otra vez, inflando `total_evaluated` y haciendo que `direction_accuracy` convergiera incorrectamente a 0%.
- **Soluci√≥n**:
  1. Se reinici√≥ el contenedor ML con `docker compose restart ml-inference`.
  2. Se reemplaz√≥ el check in√∫til `entry.get("evaluated")` por un Redis Set llamado `evaluated_timestamps`. Cada predicci√≥n evaluada se marca con `SADD evaluated_timestamps <ts>` y se verifica con `SISMEMBER` antes de evaluar. Los timestamps viejos (>5 min) se limpian autom√°ticamente para no crecer infinitamente.
  3. Se limpiaron las keys contaminadas: `DEL prediction_history prediction_accuracy evaluated_timestamps`.
- **Verificaci√≥n**: Tras 90 segundos, `total_evaluated: 2` (correcto), `direction_accuracy: 50%` (dato real), `evaluated_timestamps: 2` (sin duplicados).
