# üìì Registro de Errores y Lecciones Aprendidas ‚Äî CryptoLake

Este documento detalla los fallos t√©cnicos, errores de configuraci√≥n y problemas de compatibilidad encontrados durante el desarrollo del proyecto y c√≥mo se resolvieron.

## 1. Capa de Serving (FastAPI)

### ‚ùå Error de Dependencias en el Contenedor
- **Problema**: El contenedor `api` no ten√≠a instaladas las librer√≠as necesarias para conectarse a Iceberg (`pyiceberg`) ni para procesar datos tabulares (`pyarrow`, `s3fs`).
- **Error**: `ModuleNotFoundError: No module named 'pyiceberg'`.
- **Soluci√≥n**: Se actualizaron los requerimientos en `docker/api/Dockerfile` y se reconstruy√≥ la imagen incluyendo `pyiceberg[s3fs,pyarrow]`.

### ‚ùå Incompatibilidad de Atributos en PyArrow
- **Problema**: Se intent√≥ usar `pyarrow.compute.max_element_index()` para encontrar el registro m√°s reciente, pero la versi√≥n instalada en el contenedor no inclu√≠a ese atributo.
- **Error**: `AttributeError: module 'pyarrow.compute' has no attribute 'max_element_index'`.
- **Soluci√≥n**: Se cambi√≥ la l√≥gica t√©cnica a un ordenamiento manual basado en Python (`sorted(rows, key=lambda x: x["date"], reverse=True)[0]`), garantizando robustez entre versiones.

### ‚ùå Schema Mismatch (Fear & Greed)
- **Problema**: La API esperaba una columna `value_classification`, pero la tabla en Iceberg (creada por Spark) usaba simplemente `classification`.
- **Error**: `KeyError: 'value_classification'`.
- **Soluci√≥n**: Se ejecut√≥ un `DESCRIBE TABLE` en Spark para validar el schema real y se actualiz√≥ el c√≥digo de la ruta en `src/serving/api/routes/analytics.py`.

---

## 2. Ingesta y Procesamiento (Spark/Iceberg)

### ‚ùå Error de Resoluci√≥n de Host
- **Problema**: Los scripts intentaban conectar al cat√°logo de Iceberg usando `localhost:8181`, lo cual fallaba desde dentro de los contenedores Docker.
- **Error**: `ConnectionRefusedError` o nombres de host no encontrados (`spark-iceberg`).
- **Soluci√≥n**: Se estandarizaron los nombres de los servicios en `docker-compose.yml` (ej: `iceberg-rest` y `spark-master`) y se usaron las variables de entorno para inyectar los nombres de host correctos.

### ‚ùå L√≠mite de Velocidad de API (Rate Limiting)
- **Problema**: CoinGecko devolv√≠a errores al intentar descargar 365 d√≠as de historia para m√∫ltiples monedas simult√°neamente.
- **Error**: `HTTP 429 Too Many Requests`.
- **Soluci√≥n**: Se redujo el rango de descarga inicial a 90 d√≠as y se a√±adi√≥ l√≥gica de espera (`time.sleep`) entre llamadas en los extractores batch.

### ‚ùå Falta de JARs para Streaming
- **Problema**: Spark no pod√≠a leer de Kafka porque faltaba el conector Maven necesario.
- **Error**: `java.lang.ClassNotFoundException: org.apache.spark.sql.kafka010.KafkaSourceProvider`.
- **Soluci√≥n**: Se a√±adi√≥ el par√°metro `--packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0` al comando `spark-submit` en el job de streaming.

---

## 3. Infraestructura y Docker

### ‚ùå Configuraci√≥n de S3 (MinIO)
- **Problema**: PyIceberg y Spark ten√≠an problemas para encontrar los buckets si no se especificaba el `path-style access`.
- **Soluci√≥n**: Se forz√≥ `s3.path-style-access: "true"` en todas las configuraciones de cat√°logo para asegurar compatibilidad con MinIO.

### ‚ùå Persistencia de Datos
- **Problema**: Al reiniciar los contenedores sin vol√∫menes definidos, el cat√°logo de Iceberg perd√≠a el estado de las tablas aunque los archivos estuvieran en MinIO.
- **Soluci√≥n**: Se aseguraron vol√∫menes persistentes para `minio-data` y se configur√≥ el cat√°logo REST para ser la "fuente de verdad".
